[{
    "title": "Recreating Proxmox Ve Xtermjs in Go",
    "date": "",
    "description": "",
    "body": "Part of a hobby of mine is running a home lab and using on Proxmox VE to do the virtualization. Since I work in the space I\u0026rsquo;m slowly trying to build tooling around Proxmox that will let me use the home lab full time for work. Usually my work involves building Kubernetes management tooling, you can imagine waiting for public cloud APIs all day can take away hours of your day at cost to your employer for both your time and the compute resources.\nThere\u0026rsquo;s also a real problem today with cloud offerings of Windows. Booting a Windows 2019 or 2022 server in Amazon EC2 today can take up to 4 or 5 minutes before you are given access to the Administrator password. If you build up and tear down constantly the waiting can get tiring. Proxmox just runs qemu under the hood and with snapshotting I Just get everything working and take a quick snapshot. When I want to roll back a cluster for another provision run I can simply shut down the VMs and restore from backup and up and running again in no time.\ngo-proxmox To accomplish everything I\u0026rsquo;ll need I first started out building a Go client for Proxmox. Go is my primary language and gives everything will need to start from a well-built with proper Go types for all responses. This is in comparison to the most popular Go client which uses map[string]interface{} for everything. Beyond mapping REST endpoints to structs the real power of the client will be to build in functions to more easily automate things PVE gives you access too but forces you to the host cli as they haven\u0026rsquo;t built the tooling into their API/UI yet.\nA great example of this is loading a VM from a qcow disk image. A wonderfully simple image format and the way we want to use them for work is to specify a local network storage URL and tell Proxmox to pull and build a VM from the image, all things possible in qemu directly on the host as per Jamie Phillips' blog post which outlines the idea.\nxterm.js Backwards Engineering I wanted to recreate what the UI was doing to get on to a host, it\u0026rsquo;s native and works right out of the box with no extra additions to Proxmox after installation. Back tracing how some of this worked I went down some rabbit holes looking into implementing a VNC client in Go. There are some people who have built have some packages 1 2 but all I was trying to do is get on the Debian host and make some calls and this was overkill.\nI traced back the xterm.js functionality built into the UI and landed on exactly what I needed\u0026hellip; for reference here is the entire `main.js file I found used and I\u0026rsquo;ll walk you through how I backwards engineered it in Go and got exactly what I wanted.\nStep 1, websocket connection Grab gorilla/websocket and negotiate the connection. While reading the implementation you notice quite quickly they reuse xterm.js for nodes, qemu and lxc. This was huge because it meant I could implement this code once and get triple the usage. There is a limitation to using this with qemu but the host nodes and lxc work right out of the box. I opened the shell to a node and started backwards engineering the UI requests.\nYou can see in the bottom right there is a call to termproxy then immediately to vncwebsocket. This was easily confirmed by the Proxmox API docs and validated my suspicious that this code could be reusable as node (termproxy vncwebsocket), qemu (termproxy vncwebsocket) and lxc (termproxy vncwebsocket) all had duplicate API endpoints. Reading the main.js you can quite clearly see every where socket.send() is called and decode the login, ping and data send along with what looks like a resizer if you make your browser bigger or smaller. This was perfect, everything I needed to get into the host and send shell commands!\nStep 2, recreating the login Recreating the login was trivial, call to the termproxy endpoint results in a response which includes a user and a ticket. Call to the web socket with those in the get params and the web socket boots right up, just make sure you pass the PVEAuthCookie header in the dialer.\nThe socket only sends/receives binary messages so the next step is to start negotiating the web socket to elevate your permissions to send commands to the host. The first thing the Javascript did was login again via the socket and in Go after connected simply do\nerr := conn.WriteMessage(websocket.BinaryMessage, []byte(vnc.User+\u0026#34;:\u0026#34;+vnc.Ticket+\u0026#34;\\n\u0026#34;)) if err != nil { // handle } Read the next message for OK response from the server\u0026hellip;\n_, msg, err := conn.ReadMessage() if err != nil || string(msg) != \u0026#34;OK\u0026#34; { // handle } That\u0026rsquo;s it for connecting and logging into the websocket, you can now start sending commands\nStep 3, adding functionality Go lets you effortlessly manage the concurrency of a web socket and give you some standard interfaces for someone implementing the client\u0026rsquo;s VNC Web Socket feature. To do this I setup standard string channels for send/receive and an additional errors channel. Since you need to close everything when you\u0026rsquo;re done I also added a helpful closer func to make sure everything is cleaned up and you\u0026rsquo;re not leaking resources.\nThe function signature looked like this:\nfunc (c *Client) VNCWebSocket(path string, vnc *VNC) (chan string, chan string, chan error, func() error, error) And this will let the client manage things the consumer doesn\u0026rsquo;t care about like the keep alive. To interface with the web socket you will need to spin off two go routines, one for reading the web socket and one for writing to the web socket. You can\u0026rsquo;t concurrently write to a web socket or you\u0026rsquo;ll panic so try and make sure you\u0026rsquo;re keeping a clean select statement, or you will accidentally write to the socket twice.\nTo perform the keep alive it was quite obvious they\u0026rsquo;re sending a binary 2 for a ping so to recreate that I simply added a case for a 30s ticker.\ncase \u0026lt;-ticker.C: c.log.Debugf(\u0026#34;sending wss keep alive\u0026#34;) if err := conn.WriteMessage(websocket.BinaryMessage, []byte(\u0026#34;2\u0026#34;)); err != nil { errors \u0026lt;- err } You also want to close the socket when youre done so another case is a simple CloseMessage with an empty []byte{} which will only happen when the closer is called by the client implementor.\ncase \u0026lt;-done: if err := conn.WriteMessage(websocket.CloseMessage, []byte{}); err != nil { errors \u0026lt;- err } return To support terminal resizing I decided to add a height/width calculator and implement a watcher to notify the web socket in the event the user resizes the terminal. To get the terminal size I used buger/goterm. I simply captured the height/width when the func is called and pass it to a go routine to check every second and notify a channel if it changes and obeys the done channel closed by the closer.\ntype size struct { height int width int } // start the session by sending user@realm:ticket tsize := size{ height: goterm.Height(), width: goterm.Width(), } resize := make(chan size) go func(tsize size) { ticker := time.NewTicker(1 * time.Second) defer ticker.Stop() for { select { case \u0026lt;-done: return case \u0026lt;-ticker.C: resized := size{ height: goterm.Height(), width: goterm.Width(), } if tsize.height != resized.height || tsize.width != resized.width { tsize = resized resize \u0026lt;- resized } } } }(tsize) And catch the resize in a case in the go routine for the web socket send\u0026hellip;\ncase resized := \u0026lt;-resize: c.log.Debugf(\u0026#34;resizing terminal window: %d x %d\u0026#34;, resized.height, resized.width) if err := conn.WriteMessage(websocket.BinaryMessage, []byte(fmt.Sprintf(\u0026#34;1:%d:%d:\u0026#34;, resized.height, resized.width))); err != nil { errors \u0026lt;- err } Finally, all we need to do is send/receive messages on the channel. I wanted the implementor to call the VNCWebSocket func and send and receive strings. I added the channels and handled them by converting to a []byte and sending the message format as specified in the xterm.js version\ncase msg := \u0026lt;-send: m := []byte(msg) send := append([]byte(fmt.Sprintf(\u0026#34;0:%d:\u0026#34;, len(m))), m...) if err := conn.WriteMessage(websocket.BinaryMessage, send); err != nil { errors \u0026lt;- err } if err := conn.WriteMessage(websocket.BinaryMessage, []byte(\u0026#34;0:1:\\n\u0026#34;)); err != nil { errors \u0026lt;- err } The entire receive go routine is pretty easy but has some nice to have added error checking and is as follows\u0026hellip;\ngo func() { for { select { case \u0026lt;-done: return default: _, msg, err := conn.ReadMessage() if err != nil { if strings.Contains(err.Error(), \u0026#34;use of closed network connection\u0026#34;) { return } if !websocket.IsUnexpectedCloseError(err, websocket.CloseGoingAway, websocket.CloseAbnormalClosure) { return } errors \u0026lt;- err } recv \u0026lt;- string(msg) } } }() Step 4, using the string channels For simple testing I just tried to gety ls -la, hostname and exit which was basically the following\u0026hellip;\nvnc, err := node.TermProxy() assert.Nil(t, err) send, recv, errs, close, err := node.VNCWebSocket(vnc) assert.Nil(t, err) defer close() go func() { for { select { case msg := \u0026lt;-recv: if msg != \u0026#34;\u0026#34; { fmt.Println(\u0026#34;MSG: \u0026#34; + msg) } case err := \u0026lt;-errs: if err != nil { fmt.Println(\u0026#34;ERROR: \u0026#34; + err.Error()) return } } } }() send \u0026lt;- \u0026#34;ls -la\u0026#34; time.Sleep(10 * time.Second) send \u0026lt;- \u0026#34;hostname\u0026#34; time.Sleep(10 * time.Second) send \u0026lt;- \u0026#34;exit\u0026#34; time.Sleep(5 * time.Second) It ends up looking quite easy, just grab the TermProxy vnc response which includes the ticket, pass to VNCWebSocket and you get your string channels, error channel and a closer. Start a go routine to watch the receive and error channels and start sending messages to the send channel.\nStep 5, testing\u0026hellip; The output from my test looked like the following with all debug enabled and you can see you can interact with the host with no restrictions right from Go.\n[DEBUG] [WSS] wss://192.168.1.87:8006/api2/json/nodes/i7/vncwebsocket?port=5900\u0026amp;vncticket=***** [DEBUG] sending terminal size: 55 x 134 [DEBUG] sending: ls -la MSG: ls -la MSG: Linux i7 5.13.19-2-pve #1 SMP PVE 5.13.19-4 (Mon, 29 Nov 2021 12:10:09 +0100) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. MSG: Last login: Sun Feb 6 18:27:16 MST 2022 on pts/0 MSG: root@i7:~# ls -la MSG: total 49 drwx------ 3 root root 9 Dec 9 12:40 . drwxr-xr-x 18 root root 24 Sep 10 18:30 .. -rw------- 1 root root 2279 Feb 6 18:27 .bash_history -rw-r--r-- 1 root root 571 Apr 10 2021 .bashrc -rw-r--r-- 1 root root 25 Sep 10 18:29 .forward -rw-r--r-- 1 root root 161 Jul 9 2019 .profile -rw------- 1 root root 1024 Sep 10 18:34 .rnd drwxr-xr-x 2 root root 6 Sep 10 18:31 .ssh -rw-r--r-- 1 root root 206 Jan 23 08:41 .wget-hsts MSG: root@i7:~# [DEBUG] sending: hostname MSG: hostname MSG: i7 MSG: root@i7:~# [DEBUG] sending: exit MSG: exit MSG: MSG: logout --- PASS: TestNode_TermProxy (26.17s) Wrap Up Time to build more tooling on top of this which I\u0026rsquo;m hoping one day will be a terraform provider, a Terminal UI and a Machine Driver.\n",
    "ref": "/blog/2022/02/recreating-proxmox-ve-xtermjs-in-go/"
  },{
    "title": "Practical Cue Example, Produce YAML Config from Go Types",
    "date": "",
    "description": "",
    "body": "I recently had to spend some time to learn Cue and felt the examples/tutorials were a bit lacking and the paradigm shift to the entire language sort of messed with my head and some things Cue does were a bit foreign to me. To get started, note that the two places I spent all of my time to get this information came from their main docs and a community Cuetorials site. This will be a tutorial on how you can use Cue to generate two different YAML documents using Cue all starting with Go types to generate Cue files.\nAs Cue changes this could become out of date, this was all done using Cue v0.4.1. All code for this tutorial can be found in this github repository.\nPrerequisites You\u0026rsquo;ll need to install Cue and I recommend you get some basic understanding of the cli commands as there is some power there for your project. I also recommend you get used to modules and the mod command and the directory structure it will create for you. Note the Cue takes a lot of it\u0026rsquo;s packaging and generating inspiration from Go itself so if you\u0026rsquo;ve already done some of this in Go you may already recognize some of these features.\nGo Types to Config YAML Here is a simple scenario we will use to setup this example, we are building a server daemon in Go with a --config flag which is a file path to a YAML configuration document for database drive application with host/port configurations along with a worker pool setting for processing a work queue.\nSample Config:\napp: host: mydomain.com post: 443 workers: 2 db-dsn: root:test@tcp(mysql.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local This idea is actually pretty simple from Cue\u0026rsquo;s perspective if you write this up by hand but what makes your life easier is if the Go types generate your Cue files so you can import the types into your app and consume your generated config file via unmarshalling.\nSetting Up the Cue Module To get this project setup you\u0026rsquo;ll probably want to use a sub-directory in your project and intialize it as a cue module and place a go file with some types at the root.\n$ cd config $ cue init mod github.com/username/project/config And put your types into the types.go file\npackage config type Config struct { App App `json:\u0026#34;app\u0026#34;` } type App struct { Host string `json:\u0026#34;host\u0026#34;` Port int `json:\u0026#34;port\u0026#34;` Workers int `json:\u0026#34;workers\u0026#34;` DSN string `json:\u0026#34;dsn\u0026#34;` } Your directory structure will look like the following:\n./demo/config$ tree . ├── cue.mod │ ├── module.cue │ ├── pkg │ └── usr └── types.go Now generate your Cue files from the go types\u0026hellip;\ncue get go . Which will create a gen directory with some pathing to a types_go_gen.cue file which contains the following.\n// Code generated by cue get go. DO NOT EDIT. //cue:generate cue get go github.com/luthermonson/tutorials-2022-01-cue/config package config #Config: { app: #App @go(App) } #App: { host: string @go(Host) port: int @go(Port) workers: int @go(Workers) dsn: string @go(DSN) } Now let\u0026rsquo;s use this newly generated file in a super basic cue file to generate our sample YAML document.\npackage config import \u0026quot;github.com/luthermonson/tutorials-2022-01-cue/config\u0026quot; #config: config.#Config \u0026amp; { app: config.#App \u0026amp; { host: \u0026quot;mydomain.com\u0026quot; port: 443 workers: 2 dsn: \u0026quot;root:test@tcp(mysql.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026quot; } } #config I recommend you put this cue file in a sub-directory like ./config/cue so you can do something like this\u0026hellip;\n$ cd ./config $ cue export ./cue --out yaml app: host: mydomain.com port: 443 workers: 2 dsn: root:test@tcp(mysql.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local Using Tags in Cue for Better Config Files Tags are a construct in Cue to let you pass in variables at call time so let\u0026rsquo;s change our Cue file to use tags and consume some environment files based on tag to generate two YAML files. Change the main.cue file to set host/workers/dsn as a variable\u0026hellip;\npackage config import \u0026quot;github.com/luthermonson/tutorials-2022-01-cue/config\u0026quot; #config: config.#Config \u0026amp; { app: config.#App \u0026amp; { host: #host port: 443 workers: #workers dsn: #dsn } } #config add prod.cue\n@if(prod) package config #host: \u0026quot;mydomain.com\u0026quot; #workers: 16 #dsn: \u0026quot;root:prod@tcp(mysql-prod.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026quot; add qa.cue\n@if(qa) package config #host: \u0026quot;qa.mydomain.com\u0026quot; #workers: 1 #dsn: \u0026quot;root:qa@tcp(mysql-qa.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026quot; Now when you run cue export pass a -t qa or -t prod. The @if() at the top of the file will check if the tags are set and only include those files if the tag was passed. This is a different pattern than say only evaluating certain cue files like cue eval main.cue prod.cue and cue eval main.cue qa.cue which is a pattern outlined by this tutorial. I like the benefits of evaluating cue on a directory of files and passing tags at call time instead of having to figure out which files within the directory need evaluating.\n$ cue export ./cue -t prod --out yaml app: host: mydomain.com port: 443 workers: 16 dsn: root:prod@tcp(mysql-prod.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local $ cue export ./cue -t qa --out yaml app: host: qa.mydomain.com port: 443 workers: 1 dsn: root:qa@tcp(mysql-qa.domain.com:3306)/test?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local Conclusion Please checkout the code for this tutorial on the github repository. This was ultimately a very basic interpretation of the Cue language itself but gives you some ideas for structuring your Cue modules. The language is far more feature rich than this tutorial gives it credit and I will likely do followup blog post on the language itself after and using it to validate your configuration files before they ever hit your application runtime.\n",
    "ref": "/blog/2022/01/practical-cue-example/"
  },{
    "title": "Free Blog Hosting Using Hugo + Github Pages",
    "date": "",
    "description": "Upgrade your Personal Blog Game with Apex Records for No Cost",
    "body": "Since I just rode this merry-go-round here is a quick overview of how you can achieve a professional looking personal blog with custom DNS with minimal effort at no cost and completely run out of a single Github Repository.\nPrerequisites You\u0026rsquo;ll need to do your own homework on how to use Hugo and you should have a Github account and have a decent understanding of using git and getting changes committed and pushed to a repo. You should also have a domain and know how to do some basic DNS changes. Note that the only thing you likely can\u0026rsquo;t get for free is a domain name as there are registration costs through registrars but, you can get introductory $0.99USD domains for the first year if you shop around and don\u0026rsquo;t care the TLD you end up with. For reference, luth.io cost me $30/year to register with CloudFlare.\nDNS Do this part first\u0026hellip; it can take a while to propagate depending on your provider and it will just make your life easier getting it out of the way. What you are trying to do is use Github Pages with an Apex record for your domain. This will let something like https://luth.io be the place where people find your blog. Apex record support for a hosting service will let you bypass using subdomains like https://blog.luth.io which are called CNAMEs in DNS terms. You\u0026rsquo;re looking for A, ALIAS or ANAME records which when pointed at the root of your domain need to be an IP address.\nThis requires Github Pages to support Apex records and provide IP addresses to point your DNS too. This was easily found as there is an entire write-up available from Github Pages help documentation. Following the advice from the article you will need to configure 4 A records and 4 AAAA records and for validation with Github you should add a CNAME for www pointed to your Github Pages username DNS e.g. luthermonson.github.io.\n# A Records 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 # AAAA Records 2606:50c0:8000::153 2606:50c0:8001::153 2606:50c0:8002::153 2606:50c0:8003::153 # CNAME www \u0026lt;githubusername\u0026gt;.github.io When configured through Cloudflare my DNS entries looked like the following, note that skipping the proxy and doing a grey cloud \u0026ldquo;DNS Only\u0026rdquo; was intentional as the proxy will with SSL will cause an infinite redirect loop and Github takes care of SSL for you.\nVerifying your Domain with Github You will need to add your domain to Github and add a DNS TXT record to be able to add it to a repository later. Go to your Github Pages settings for your account (not repository) and Click \u0026ldquo;Add a Domain\u0026rdquo; and follow the instructions by typing your domain, clicking next and getting the DNS TXT records to validate your Domain with Github Pages.\nGrab the details from the Verification Step, add the TXT record to your DNS Provider and then click Verify.\nGithub Repository You will need a Github Repository to house your Hugo blog and all the content, this will be where you serve your pages. Play with Hugo and create your blog, pick a theme and get used to the Huge tool chain. Hugo will create a directory structure, by default when you run the hugo cli command it will generate your blog and place all contents in the ./public directory. Github Pages can NOT serve from anything other than the root ./ and the subdirectory ./docs and for our purposes to serve from one Github Repository we will use ./docs. To fix Hugo to publish to ./docs you can simply add to the config.toml a config line of publishDir = \u0026quot;docs\u0026quot;. When you now run hugo cli it will generate all files to the ./docs directory and prime your repository for serving via Github Pages.\nTo get Github Pages to serve the contents of your Blog with your domain you will need to configure the Pages settings for the repository. Check all your code into a branch and configure your Pages settings like the following. Summary If you configure your DNS properly and use the free Github Pages service you can easily host your personal blog at no cost on your own personal vanity domain name from a single Github Repository. Configure Hugo to use the ./docs directory to adhere to Pages standards then you\u0026rsquo;ll be able to effortlessly set up your Blog. Go henceforth and buy up some novelty domain names and get to blogging!\nLinks  Hugo Cloudflare Free DNS Service Github Github Pages  ",
    "ref": "/blog/2022/01/free-personal-blog-hugo-github-pages/"
  },{
    "title": "Introduction",
    "date": "",
    "description": "",
    "body": "Getting a blog up and running to get some of the thoughts out of my head and into a markdown file. For reference on who I am please check out the about section and stay tuned for more content related to what it is I do everyday.\n",
    "ref": "/blog/introduction/"
  },{
    "title": "About the Blogger",
    "date": "",
    "description": "",
    "body": "Originally born and raised in the Midwest, Luther moved to the expansive deserts of the American Southwest after receiving a Bachelor of the Arts in Computer Science from Gustavus Adolphus College in Southern Minnesota. After moving to Arizona, Luther spent his career building web APIs and utilities for various industries in PHP and NodeJS before migrating to Open Source DevOps tooling using Containers and Virtualization.\nLuther is an Open Source developer mostly writing Go and working in the Kubernetes space by way of his employer SUSE and their Multi-Cluster Management tool Rancher. As the Team Lead for the Windows on Rancher he has spent time specializing in Kubernetes working on alternative operating systems and architectures including arm64 and s390x. Working in this unique space and working from home full time has made him a home lab aficionado and consumer of Proxmox VE.\nContributions to the Rancher and open source:\n vSphere Node Driver Rancher Machine Flannel RKE1 and RKE2 govmomi  Personal Projects:\n goodhosts go-proxmox quiso  ",
    "ref": "/about/"
  }]
